{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b1cce0-2fbf-41df-8b14-634ab12f0b7d",
   "metadata": {},
   "source": [
    "# III Neuroniniai tinklai (PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e67a41-e530-4ccf-9018-7c7de5871e7e",
   "metadata": {},
   "source": [
    "## XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603944a-317c-49f8-990d-a2da13318ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5590220e-7775-4ee3-a8fc-ec741c59aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e7f807-3839-47bd-a06b-833624d404da",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE     = 'cpu'\n",
    "#DEVICE     = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_EPOCHS = 250\n",
    "FILE_DIR   = '/content/drive/My Drive/Colab Notebooks/xor_data_II.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd0e8d-acc7-497c-9ce0-ea2cd483676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(FILE_DIR)\n",
    "X    = data[['x1', 'x2']].values\n",
    "y    = data['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98588dae-560b-4060-9e7e-3c8dd460dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plt.scatter(*X[y==0].T, marker='o', s=80, c='b')\n",
    "plt.scatter(*X[y==1].T, marker='o', s=80, c='g')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86cb38-1be2-46e3-a53a-57a29cb0ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLinear(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_hidden_1, num_classes):\n",
    "        super(MLPLinear, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.linear_1   = torch.nn.Linear(num_features, num_hidden_1)\n",
    "        self.linear_out = torch.nn.Linear(num_hidden_1, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.linear_1(x)\n",
    "        #out = F.relu(out)\n",
    "        \n",
    "        logits = self.linear_out(out)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47305a30-ac5e-4d09-9b33-5ae739a4fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model     = MLPLinear(num_features=2, num_hidden_1=50, num_classes=2)\n",
    "model     = model.to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625be00a-ec5b-4de5-a56a-920c19bda01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time     = time.time()\n",
    "minibatch_cost = []\n",
    "\n",
    "features = torch.tensor(X, dtype=torch.float).to(DEVICE)\n",
    "targets  = torch.tensor(y, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    logits, probas = model(features)\n",
    "    cost           = F.cross_entropy(logits, targets)\n",
    "   \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    minibatch_cost.append(cost)\n",
    "    optimizer.step()\n",
    "\n",
    "    print (f'epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | cost: {cost:.4f}')\n",
    "    \n",
    "print(f'laikas:{((time.time() - start_time)/60):.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bdeaa0-508c-4594-b4e9-13105a46a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    tensor = torch.tensor(np.array([xx1.ravel(), xx2.ravel()]).T).float()\n",
    "    logits, probas = classifier.forward(tensor)\n",
    "    Z = np.argmax(probas.detach().numpy(), axis=1)\n",
    "\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    \n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "                    alpha=0.8, color=cmap(idx),\n",
    "                    edgecolor='black',\n",
    "                    marker=markers[idx], \n",
    "                    label=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8eb7c-87c1-4187-9497-9ab4db6b7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(features, targets, classifier=model)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af3058-7a13-4de3-a116-3e28982c404f",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41212c74-ed29-4990-971b-11bc23462398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9443575f-7f3b-486b-b4d6-46071f4cd8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 100\n",
    "DEVICE     = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2998dbc-183b-4d8b-b7b8-229902215c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5c9f1-0eb8-4523-9f3e-f926a63ad0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_hidden, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        ### 1st hidden layer\n",
    "        self.linear_1 = torch.nn.Linear(num_features, num_hidden)\n",
    "        self.linear_1.weight.detach().normal_(0.0, 0.1)\n",
    "        self.linear_1.bias.detach().zero_()\n",
    "\n",
    "        ### Output layer\n",
    "        self.linear_out = torch.nn.Linear(num_hidden, num_classes)\n",
    "        self.linear_out.weight.detach().normal_(0.0, 0.1)\n",
    "        self.linear_out.bias.detach().zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear_1(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        logits = self.linear_out(out)\n",
    "        #probas = torch.softmax(logits, dim=1)\n",
    "        return logits#, probas\n",
    "\n",
    "model = MLP(num_features=28*28, num_hidden=100, num_classes=10)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "def compute_loss(net, data_loader):\n",
    "    curr_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for cnt, (features, targets) in enumerate(data_loader):\n",
    "            features = features.view(-1, 28*28).to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            logits = net(features)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            curr_loss += loss\n",
    "        return float(curr_loss)/cnt\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "minibatch_cost = []\n",
    "epoch_cost = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.view(-1, 28*28).to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits = model(features)\n",
    "        \n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "       \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        minibatch_cost.append(cost.item())\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost.item()))\n",
    "        \n",
    "    cost = compute_loss(model, train_loader)\n",
    "    epoch_cost.append(cost)\n",
    "    print('Epoch: %03d/%03d  kaina: %.4f' % (\n",
    "            epoch+1, NUM_EPOCHS, cost))\n",
    "    print(f'epochos laikas: {((time.time() - start_time)/60):.2f} min')\n",
    "    \n",
    "print(f'visas laikas: {((time.time() - start_time)/60):.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f69c29-b693-4c14-ab83-c198f4eaa44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(14,8))\n",
    "ax[0].plot(range(len(minibatch_cost)), minibatch_cost, label='mini batch')\n",
    "ax[0].ylabel('Cross Entropy')\n",
    "ax[0].xlabel('Minibatch')\n",
    "\n",
    "ax[1].plot(range(len(epoch_cost)), epoch_cost, label='epocho kaina')\n",
    "ax[1].ylabel('Cross Entropy')\n",
    "ax[1].xlabel('Epoch')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b51db-3c07-4498-9cd8-5cf6e7c4e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(net, data_loader):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.view(-1, 28*28).to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            logits = net.forward(features)\n",
    "            predicted_labels = torch.argmax(logits, 1)\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "        return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "print(f'Treniravimo tikslumas: {compute_accuracy(model, train_loader).2f}')\n",
    "print(f'Testavimo    tikslumas: {compute_accuracy(model, test_loader).2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
